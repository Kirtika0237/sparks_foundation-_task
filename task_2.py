# -*- coding: utf-8 -*-
"""TASK_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FMSXDsyiJV697MLaprZ7J8j9alncCraC

The Sparks Foundation Task 2: Prediction using Unsuperwised Machine Learning

Task2: predict optimum cluster for the dataset.

Step 1:importing the data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.cluster import KMeans

"""reading the dataset"""

#reading the iris dataset
df=pd.read_csv("Iris.csv")
df.head()

"""**Step 2: Visualising the data**"""

df.tail()

df.shape

df.columns

df['Species'].unique()

df.info()

df.describe()

"""This is an unsuperwised machine learning so we hate to drop the 2 columns Id and Species."""

iris=pd.DataFrame(df)
iris_df=iris.drop(columns=["Id","Species"])
iris_df.head()

"""Step 3:finding the optimum number of clusters"""



"""The **Elbow Method** is a visual approach used to determine the ideal ‘K’ (number of clusters) in K-means clustering. It operates by calculating the Within-Cluster Sum of Squares (WCSS), which is the total of the squared distances between data points and their cluster center."""

# Initialize the list
within_cluster_sum_of_squares = []

# Calculate the within-cluster sum of squares for different k values
cluster_range = range(1, 15)
for k in cluster_range:
    km = KMeans(n_clusters=k)
    km.fit(iris_df)
    within_cluster_sum_of_squares.append(km.inertia_)

"""Plotting the wcss against clusters range

"""

plt.plot(cluster_range,within_cluster_sum_of_squares,'go--',color='green')
plt.title("The elbow method")
plt.xlabel("Numbers of clusters")
plt.ylabel("Within_cluster_sum_of_squares")
plt.grid()
plt.show()

"""we can clearly says that the optimum clusters are found at elbow becuase the wcss doesn't decrease significantly with every iteration.

Step 4: Applying K-Means Clustering
"""

from sklearn.cluster import KMeans
model=KMeans(n_clusters=3,init='k-means++',max_iter=300,n_init=10,random_state=0)
predictions=model.fit_predict(iris_df)

"""Step 5:visualising the clusters"""

x=iris_df.iloc[:,[0,1,2,3]].values
plt.scatter(x[predictions==0,0],x[predictions==0,1],s=25,c='red',label='Iris-setosa')
plt.scatter(x[predictions==1,0],x[predictions==1,1],s=25,c='blue',label='Iris-versicolour')
plt.scatter(x[predictions==2,0],x[predictions==2,1],s=25,c='green',label='Iris-virginica')

#plotting the cluster's center
plt.scatter(model.cluster_centers_[:,0],model.cluster_centers_[:,1],s=100,c='yellow',label='Centroids')
plt.legend()
plt.grid()
plt.show()